{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NX90YLtow5S5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400560fa-1ad7-4f3a-8190-3cb2724ffc4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.2\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "####### It's commonly used in natural language processing tasks, especially in machine translation and text generation, where it allows for more flexible and efficient tokenization compared to traditional word-based tokenization methods.\n",
        "# !pip install sentencepiece\n",
        "####### Function: SacreBLEU is a library for computing the BLEU (Bilingual Evaluation Understudy) score, which is a metric used to evaluate the quality of machine-translated text.\n",
        "####### Usage: It's widely used in the field of machine translation to assess the performance of machine translation systems. BLEU score compares the output of a machine translation system to one or more human reference translations and assigns a score based on the similarity between the machine translation and the reference translations\n",
        "# !pip install sacrebleu\n",
        "####### Function: TorchData is a library for handling datasets and data loading in PyTorch.\n",
        "####### Usage: It provides utilities for creating custom datasets, data loaders, and data transformations. TorchData simplifies the process of working with datasets in PyTorch, making it easier to load and preprocess data for training machine learning models.\n",
        "# !pip install torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gu81h7nsw_iK"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass          #Dataclasses provide a way to create classes in Python with less boilerplate code for common tasks like initializing objects, adding comparison methods, and more.\n",
        "import numpy as np\n",
        "import math\n",
        "import sacrebleu                         #is a popular metric used to evaluate the quality of machine-translated text.\n",
        "import sentencepiece as spm              #SentencePiece is a popular library for tokenizing text, especially in natural language processing tasks like machine translation.\n",
        "import torch                             #a popular deep learning framework for building and training neural networks.\n",
        "import torch.nn as nn\n",
        "from torch import utils                  # PyTorch's utils module contains various utility functions and classes for tasks such as data loading and manipulation.\n",
        "from torchtext.datasets import Multi30k  # Multi30k is a dataset commonly used for machine translation tasks, containing parallel sentences in multiple languages.\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm                     #package that provides a progress bar during iterations,\n",
        "from numpy.lib.utils import lookfor       #function in the NumPy library that helps you search for specific keywords in NumPy's documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2Oase4NYwky",
        "outputId": "23d7bc72-d4ec-400a-815b-a5e51a06a2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is :  cuda\n"
          ]
        }
      ],
      "source": [
        "# This sets the random seed to 7, which is used to initialize random number generators. Setting a random seed ensures reproducibility in experiments involving randomization.\n",
        "# this means that we need to select a specific  data \"known\"  to help us if we needed to compare between experiments or any thing like that\n",
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")          #This line determines whether a CUDA-compatible GPU is available on the system. If a GPU is available, the code assigns the device to CUDA; otherwise, it assigns it to CPU. This is crucial for running PyTorch code on the appropriate hardware.\n",
        "print(\"Device is : \",DEVICE)\n",
        "\n",
        "SRC = \"de\"                        # Source Language\n",
        "TRG = \"en\"                        # Target Language\n",
        "\n",
        "train_iter = Multi30k(split='train',language_pair=(SRC,TRG))                      #This line initializes a data iterator for the Multi30k dataset, specifying that it should use the training split and the language pair defined by SRC (German) and TRG (English).\n",
        "\n",
        "f_de = open('Muti30k_de_text.txt',\"w\")                        # open a files with a specific names to store data i it\n",
        "f_en = open('Muti30k_en_text.txt',\"w\")\n",
        "\n",
        "for pair in train_iter:\n",
        "    f_de.write(pair[0] + '\\n')\n",
        "    f_en.write(pair[1] + '\\n')\n",
        "\n",
        "f_de.close()\n",
        "f_en.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsdcMvj8mUZQ"
      },
      "outputs": [],
      "source": [
        "# spm.SentencePieceTrainer.train(f'--input=Muti30k_de_text.txt --model_prefix=Muti30k_de --user_defined_symbols=<pad> --vocab_size={de_vocab_size}')\n",
        "# This line trains a SentencePiece model for the German language. It uses the SentencePieceTrainer.train method to train the model. Here's what each argument means:\n",
        "\n",
        "# 1-   --input=Muti30k_de_text.txt: Specifies the input text file for training. Adjust this to your actual German text corpus file.\n",
        "\n",
        "# 2-   --model_prefix=Muti30k_de: Specifies the prefix for the model files generated during training.\n",
        "# In the context of the --model_prefix parameter in the SentencePiece library, specifying a prefix for the model files generated during training means that all the files related to the trained model will have names starting with that prefix.\n",
        "# For example, if you set --model_prefix=Muti30k_de, then the files generated during training might include:\n",
        "# Muti30k_de.model: This file typically contains the model's architecture and parameters.\n",
        "# Muti30k_de.vocab: This file contains the vocabulary generated by the model. --- represents a token along with its corresponding index and frequency in the training data\n",
        "# Other auxiliary files related to training or the model might also use the same prefix.\n",
        "# By setting a prefix, you can easily identify and manage the files associated with a particular trained model, especially if you're working with multiple models or need to organize your files systematically.\n",
        "\n",
        "# 3- --user_defined_symbols=<pad>: Defines a special symbol <pad> which can be used later for padding sequences during sequence processing tasks like machine translation or text generation.\n",
        "# 4- --vocab_size={de_vocab_size}: Specifies the vocabulary size for the German language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty5KY2v_x-cw",
        "outputId": "d2ec89f7-3255-4429-a4f3-378fcc0c6236"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Here we give the tokenizer the vocab size(unique words) we get this numbers Through experimentation to get the best suitable results\n",
        "\n",
        "en_vocab_size = 8200\n",
        "de_vocab_size = 10000\n",
        "\n",
        "vocab_sizes = {\"en\":en_vocab_size,\"de\":de_vocab_size}\n",
        "\n",
        "# make training to extract a model to work on it\n",
        "spm.SentencePieceTrainer.train(f'--input=Muti30k_de_text.txt --model_prefix=Muti30k_de --user_defined_symbols=<pad> --vocab_size={de_vocab_size}')\n",
        "spm.SentencePieceTrainer.train(f'--input=Muti30k_en_text.txt --model_prefix=Muti30k_en --user_defined_symbols=<pad> --vocab_size={en_vocab_size}')\n",
        "\n",
        "# loading and extracting models to make toknization\n",
        "de_sp = spm.SentencePieceProcessor()\n",
        "de_sp.load('Muti30k_de.model')\n",
        "\n",
        "en_sp = spm.SentencePieceProcessor()\n",
        "en_sp.load('Muti30k_en.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA35tY6760wJ",
        "outputId": "ed8b14f9-d660-49fe-ca99-2e9b9ab89a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁Ho', 'w', '▁are', '▁you', '▁doing', '?']\n",
            "[5234, 645, 20, 1277, 185, 0]\n",
            "-----------------------------------------------------\n",
            "How are you doing?\n",
            "How are you doing ⁇ \n"
          ]
        }
      ],
      "source": [
        "tokenizers = {\"en\":en_sp.encode_as_ids,\"de\":de_sp.encode_as_ids}\n",
        "detokenizers = {\"en\":en_sp.decode_ids,\"de\":de_sp.decode_ids}\n",
        "\n",
        "print(en_sp.encode_as_pieces(\"How are you doing?\"))                                 # this sentence exicted in our data\n",
        "print(en_sp.encode_as_ids(\"How are you doing?\"))\n",
        "\n",
        "print(\"-----------------------------------------------------\")\n",
        "\n",
        "print(en_sp.decode_pieces(['▁Ho', 'w', '▁are', '▁you', '▁doing', '?']))\n",
        "print(en_sp.decode_ids([5234, 645, 20, 1277, 185, 0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L49q3EQu9IwZ",
        "outputId": "587f3910-e787-4acf-fa7e-a187e3eeec13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<s>', '</s>', '<pad>', '▁a', '.', '▁A', '▁in', '▁the', '▁on', '▁is', '▁man', '▁and', '▁of', '▁with', 's', 'ing', '▁', ',', '▁woman']\n",
            "['<unk>', '<s>', '</s>', '<pad>', '.', '▁eine', '▁Ein', 'm', '▁in', '▁mit', ',', '▁und', '▁auf', '▁ein', '▁Mann', '▁einer', '▁Eine', 'n', '▁der', '▁Frau']\n"
          ]
        }
      ],
      "source": [
        "print([en_sp.id_to_piece(id) for id in range(20)])\n",
        "print([de_sp.id_to_piece(id) for id in range(20)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LPrEzBN693Ux"
      },
      "outputs": [],
      "source": [
        "# the variables UNK, BOS, EOS, and PAD are assigned integer values: 0, 1, 2, and 3, respectively. These values likely represent special tokens used in natural language processing tasks, such as machine translation or language modeling. Here's what these tokens typically stand for:\n",
        "\n",
        "# UNK: Short for \"Unknown,\" this token is often used to represent words that are not found in the vocabulary during tokenization or encoding. When a word in the input text is not present in the model's vocabulary, it gets replaced with the UNK token.\n",
        "# BOS: Stands for \"Beginning of Sentence.\" It marks the beginning of a sentence in a sequence. This token is often used in sequence-to-sequence models, especially in tasks like machine translation, where it indicates the start of the source or target sentence.\n",
        "# EOS: Stands for \"End of Sentence.\" It marks the end of a sentence in a sequence. Similar to BOS, it's commonly used in sequence-to-sequence models to denote the end of the source or target sentence.\n",
        "# PAD: Stands for \"Padding.\" This token is used to pad sequences to a fixed length during training or inference. It ensures that all sequences in a batch have the same length, which is necessary for efficient processing in deep learning models, particularly in tasks like sequence classification or language modeling.\n",
        "# By assigning integer values to these special tokens, it becomes easier to manipulate and incorporate them into the tokenization and encoding processes within NLP models. These tokens play a crucial role in handling out-of-vocabulary words, marking sentence boundaries, and ensuring consistent sequence lengths across batches.\n",
        "\n",
        "UNK,BOS,EOS,PAD = 0,1,2,3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wkQfVD_-H3G",
        "outputId": "43e42845-ce53-46fa-f103-af53cf767fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29000\n",
            "1014\n",
            "('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', 'Two young, White males are outside near many bushes.')\n",
            "('Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.', 'Several men in hard hats are operating a giant pulley system.')\n",
            "('Ein kleines Mädchen klettert in ein Spielhaus aus Holz.', 'A little girl climbing into a wooden playhouse.')\n",
            "('Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.', 'A man in a blue shirt is standing on a ladder cleaning a window.')\n",
            "('Zwei Männer stehen am Herd und bereiten Essen zu.', 'Two men are at the stove preparing food.')\n",
            "('Ein Mann in grün hält eine Gitarre, während der andere Mann sein Hemd ansieht.', 'A man in green holds a guitar while the other man observes his shirt.')\n",
            "('Ein Mann lächelt einen ausgestopften Löwen an.', 'A man is smiling at a stuffed lion')\n",
            "('Ein schickes Mädchen spricht mit dem Handy während sie langsam die Straße entlangschwebt.', 'A trendy girl talking on her cellphone while gliding slowly down the street.')\n",
            "('Eine Frau mit einer großen Geldbörse geht an einem Tor vorbei.', 'A woman with a large purse is walking by a gate.')\n",
            "('Jungen tanzen mitten in der Nacht auf Pfosten.', 'Boys dancing on poles in the middle of the night.')\n"
          ]
        }
      ],
      "source": [
        "train_iter = Multi30k(split='train',language_pair=(SRC,TRG))                      #This line initializes a data iterator for the Multi30k dataset, specifying that it should use the training split and the language pair defined by SRC (German) and TRG (English).\n",
        "valid_iter = Multi30k(split='valid',language_pair=(SRC,TRG))\n",
        "\n",
        "# The train_iter iterator is iterated over, and for each pair of sentences (x, y) in the iterator, the rstrip('\\n') method is applied to remove trailing newline characters. Additionally, it checks if x is not an empty string (if x!=''), ensuring that only non-empty examples are included in the training set.\n",
        "train_set = [(x.rstrip('\\n'),y.rstrip('\\n')) for x,y in train_iter if x!='']\n",
        "valid_set = [(x.rstrip('\\n'),y.rstrip('\\n')) for x,y in valid_iter if x!='']\n",
        "\n",
        "print(len(train_set))\n",
        "print(len(valid_set))\n",
        "\n",
        "for i in range(10):\n",
        "  print(train_set[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PFJ1v3UGD8-Y"
      },
      "outputs": [],
      "source": [
        "# This line sets the maximum sequence length (sentence) to 50 tokens. It's common in machine translation tasks to limit the length of input and output sequences to facilitate model training and inference.\n",
        "max_seq_len = 50\n",
        "# This function tokenize_dataset takes a dataset (presumably a list of tuples where each tuple contains a source text and its corresponding target text) as input and tokenizes each example in the dataset. Here's what it does:\n",
        "\n",
        "# For each (src_text, trg_text) tuple in the dataset:\n",
        "# It tokenizes the source text (src_text) and target text (trg_text) using the tokenizers associated with the source and target languages (SRC and TRG, respectively).\n",
        "# It limits the tokenized sequences to max_seq_len - 2 tokens to leave room for the special tokens BOS (Beginning of Sentence) and EOS (End of Sentence).\n",
        "# It adds the BOS token at the beginning and the EOS token at the end of both the source and target sequences.\n",
        "# It converts the tokenized sequences into PyTorch tensors >>>> el tensores f pytorch zy el array f numpy\n",
        "def tokenize_dataset(dataset):\n",
        "  return[(torch.tensor([BOS]+tokenizers[SRC](src_text)[0:max_seq_len-2]+[EOS]),\n",
        "          torch.tensor([BOS]+tokenizers[TRG](trg_text)[0:max_seq_len-2]+[EOS]))\n",
        "            for src_text,trg_text in dataset]\n",
        "\n",
        "\n",
        "train_tokenized = tokenize_dataset(train_set)\n",
        "valid_tokenized = tokenize_dataset(valid_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qGj6dYAaFjzd"
      },
      "outputs": [],
      "source": [
        "# class  TranslationDataset, which inherits from PyTorch's Dataset class. This custom dataset class will be used to encapsulate the translation data.\n",
        "# The __init__ method is the constructor of the class. It initializes a new instance of the TranslationDataset class with the provided data. The data parameter is expected to be a list-like object containing translation data, such as tokenized sentences.\n",
        "# The __len__ method is a special method used to determine the length of the dataset. It returns the total number of examples in the dataset by returning the length of the data attribute.\n",
        "\n",
        "class TraslationDataset(Dataset):\n",
        "  def __init__(self,data):\n",
        "    self.data = data\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        " # if i needed to get an sentence with it's index\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TsQuhtBgYj55"
      },
      "outputs": [],
      "source": [
        "def pad_sequence(batch):\n",
        "  # These lines extract the source sequences (src_seqs) and target sequences (trg_seqs) from the batch of translation data. Each element in batch is a tuple containing a source sequence (src) and its corresponding target sequence (trg).\n",
        "  src_seqs = [src for src,trg in batch]\n",
        "  trg_seqs = [trg for src,trg in batch]\n",
        "  # output tensors should have the batch dimension as the first dimension. The padding_value=PAD argument specifies the value to be used for padding, where PAD is likely a predefined integer value representing a padding token.\n",
        "  src_padded = torch.nn.utils.rnn.pad_sequence(src_seqs,batch_first=True,padding_value=PAD)\n",
        "  trg_padded = torch.nn.utils.rnn.pad_sequence(trg_seqs,batch_first=True,padding_value=PAD)\n",
        "\n",
        "  return src_padded,trg_padded\n",
        "\n",
        "# Overall, this function takes a batch of translation data, pads the source and target sequences to ensure uniform lengths within the batch, and returns the padded sequences as tensors. It's a common preprocessing step used when working with sequence-to-sequence models, such as those used in machine translation tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "haBjJU2yaNMN"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "# class responsible for creating data loaders for training and validation sets ,,, allowing for efficient batch processing during model training and evaluation.\n",
        "class Dataloaders:\n",
        "  def __init__(self):\n",
        "    self.train_dataset = TraslationDataset(train_tokenized)\n",
        "    self.valid_dataset = TraslationDataset(valid_tokenized)\n",
        "    # collate_fn=pad_sequence helps handle variable-length sequences in NLP tasks, ensuring that batches of data fed into the model have consistent dimensions, which is necessary for proper training and inference.\n",
        "    self.train_loader = torch.utils.data.DataLoader(self.train_dataset,batch_size=batch_size,shuffle=True,collate_fn=pad_sequence)\n",
        "    self.valid_loader = torch.utils.data.DataLoader(self.valid_dataset,batch_size=batch_size,shuffle=True,collate_fn=pad_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0i8-TXFWaUD6"
      },
      "outputs": [],
      "source": [
        "# note that we have 8 Multi-head Attention       >>>>>>>>>   if we have 10 words > (10*512  to 512*64) >> 10*64       >>>    8*64 = 512\n",
        "# suppose d_k >> 64 ,, d_embed >> 512 , h =8   ,, 10  no of words\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self,h,d_embed,dropout=0):\n",
        "        super().__init__()\n",
        "        assert d_embed % h == 0                              #This statement ensures that the embedding dimension is divisible by the number of attention heads. This is necessary for later splitting the embedding into multiple heads.\n",
        "        self.d_k = d_embed // h\n",
        "        self.h = h\n",
        "        self.d_embed = d_embed\n",
        "        self.WQ = nn.Linear(d_embed, d_embed)                           #. It takes input of size d_embed and outputs a tensor of the same size d_embed.\n",
        "        self.WK = nn.Linear(d_embed, d_embed)\n",
        "        self.WV = nn.Linear(d_embed, d_embed)\n",
        "        self.linear = nn.Linear(d_embed,d_embed)                     #This linear layer is used as the final linear transformation after combining the outputs of the attention heads. It takes input of size d_embed and outputs a tensor of the same size d_embed.\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x_query, x_key, x_value, mask=None):\n",
        "        nbatch = x_query.size(0) # get batch size\n",
        "        # 1) Linear projections to get the multi-head query, key and value tensors\n",
        "        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n",
        "        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n",
        "        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
        "        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
        "        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
        "        # 2) Attention\n",
        "        # scores has dimensions: nbatch * h * seq_len * seq_len\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n",
        "        # 3) Mask out padding tokens and future tokens\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask, float('-inf'))\n",
        "        # p_atten dimensions: nbatch * h * seq_len * seq_len\n",
        "        p_atten = torch.nn.functional.softmax(scores, dim=-1) # attention filter\n",
        "        p_atten = self.dropout(p_atten)\n",
        "        # x dimensions: nbatch * h * seq_len * d_k\n",
        "        x = torch.matmul(p_atten, value)  # filtered values\n",
        "        # x now has dimensions:nbatch * seq_len * d_embed\n",
        "        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n",
        "        return self.linear(x) # final linear layer                                                                #In the context of the forward method of multi-head attention or similar operations, the .contiguous() method is often used after reshaping or transposing operations to ensure that the tensor is contiguous before further processing. This helps in avoiding potential issues related to non-contiguous memory layout and ensures efficient computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nlXb_x0pq3x"
      },
      "outputs": [],
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, dim, dropout):\n",
        "        super().__init__()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        #  Layer normalization helps in stabilizing the distribution of activations across different features. This can lead to faster training and improved convergence properties by reducing the internal covariate shift problem.\n",
        "        self.norm = nn.LayerNorm(dim)  # (x-M)/std\n",
        "\n",
        "    def forward(self, x, sublayer):                                   #The sublayer function (e.g., attention, feed-forward) to be applied within the residual connection.\n",
        "        return x + self.drop(sublayer(self.norm(x)))\n",
        "#Explaination\n",
        "# Layer normalization (self.norm(x)): The input tensor is normalized along the feature dimension.\n",
        "# Sublayer application (sublayer(...)): The normalized tensor is passed through the specified sublayer function (e.g., attention mechanism or feed-forward network).\n",
        "# Dropout (self.drop(...)): Dropout is applied to the output of the sublayer.\n",
        "# Residual connection (x + ...): The original input tensor x is added to the output of the dropout layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4UCYM3TvEbx"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''Encoder = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm'''\n",
        "    # config provides a convenient way to pass various configuration settings to the encoder module, allowing for flexibility and easy experimentation with different hyperparameters and settings.\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_embed = config.d_embed  # 512\n",
        "        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed) # Vocab Dictionary size , Embed size  ,,, layer converts input tokens into continuous vector representations. It's essentially a lookup table where each token is represented by a vector of config.d_embed dimensions.\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed))          #In the context of the pos_embed tensor, which has shape (1, max_seq_len, d_embed), this slicing operation is used to ensure that the positional embeddings have the same length as the input sequence.\n",
        "        self.encoder_blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.norm = nn.LayerNorm(config.d_embed)\n",
        "\n",
        "    def forward(self, input, mask=None):\n",
        "        x = self.tok_embed(input) # Vectors\n",
        "        x_pos = self.pos_embed[:, :x.size(1), :]  # Vectors'\n",
        "        x = self.dropout(x + x_pos) # update vectors with position information\n",
        "        for layer in self.encoder_blocks:\n",
        "            x = layer(x, mask) # (50,512)\n",
        "        return self.norm(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K86lIuaa1s5-"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    '''EncoderBlock: self-attention -> position-wise fully connected feed-forward layer'''\n",
        "    def __init__(self, config):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.atten = MultiHeadAttention(config.h, config.d_embed, config.dropout)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(config.d_embed, config.d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.d_ff, config.d_embed)\n",
        "        )\n",
        "        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n",
        "        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # self-attention\n",
        "        x = self.residual1(x, lambda x: self.atten(x, x, x, mask=mask))\n",
        "        # position-wise fully connected feed-forward layer\n",
        "        return self.residual2(x, self.feed_forward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuD_h8Xw2JxP"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_embed = config.d_embed\n",
        "        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed))\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n",
        "        self.norm = nn.LayerNorm(config.d_embed)\n",
        "        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n",
        "\n",
        "\n",
        "# this function generates a mask that can be used to prevent the decoder from attending to tokens at positions beyond the current position in the sequence during self-attention. This is important for ensuring that the model only attends to tokens that have already been generated during training.\n",
        "    def future_mask(self, seq_len):\n",
        "        '''mask out tokens at future positions'''\n",
        "        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n",
        "        return mask.view(1, 1, seq_len, seq_len)\n",
        "\n",
        "\n",
        "    def forward(self, memory, src_mask, trg, trg_pad_mask):\n",
        "        seq_len = trg.size(1)\n",
        "        trg_mask = torch.logical_or(trg_pad_mask, self.future_mask(seq_len))\n",
        "        x = self.tok_embed(trg) + self.pos_embed[:, :trg.size(1), :]\n",
        "        x = self.dropout(x)\n",
        "        for layer in self.decoder_blocks:\n",
        "            x = layer(memory, src_mask, x, trg_mask)\n",
        "        x = self.norm(x)\n",
        "        logits = self.linear(x)\n",
        "        return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI4usFmjbuiR"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.atten1 = MultiHeadAttention(config.h,config.d_embed,config.dropout)\n",
        "        self.atten2 = MultiHeadAttention(config.h,config.d_embed,config.dropout)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "                                    nn.Linear(config.d_embed , config.d_ff),                                #d_ff >> feed forward\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Dropout(config.dropout),\n",
        "                                    nn.Linear(config.d_ff,config.d_embed)\n",
        "        )\n",
        "        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed,config.dropout) for i in range(3)])\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,memory,src_mask,trg,trg_mask):\n",
        "        x = memory\n",
        "        y = trg\n",
        "        y = self.residuals[0](y,lambda y :self.atten1(y,y,y, mask = trg_mask))\n",
        "        y = self.residuals[1](y,lambda y :self.atten1(y,x,x, mask =src_mask))\n",
        "        return self.residuals[2](y,self.feed_forward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daxs8Po7buiR"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, src_mask, trg, trg_pad_mask):\n",
        "        return self.decoder(self.encoder(src, src_mask), src_mask, trg, trg_pad_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbPmhxfWbuiR"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ModelConfig:\n",
        "    encoder_vocab_size: int\n",
        "    decoder_vocab_size: int\n",
        "    d_embed: int\n",
        "    # d_ff is the dimension of the fully-connected  feed-forward layer\n",
        "    d_ff: int\n",
        "    # h is the number of attention head\n",
        "    h: int\n",
        "    N_encoder: int\n",
        "    N_decoder: int\n",
        "    max_seq_len: int\n",
        "    dropout: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bvy56YsbuiR"
      },
      "outputs": [],
      "source": [
        "def make_model(config):\n",
        "    model = Transformer(Encoder(config),Decoder(config)).to(DEVICE)\n",
        "    for p in model.parameters():\n",
        "        if p.dim()>1:\n",
        "            nn.init.xavier_uniform_(p)                            #Xavier uniform initialization is a common technique for initializing the weights of neural network layers to ensure stable training.\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OEnAdG1buiR"
      },
      "outputs": [],
      "source": [
        "def make_batch_input(x, y):\n",
        "        src = x.to(DEVICE)\n",
        "        trg_in = y[:, :-1].to(DEVICE)\n",
        "        trg_out = y[:, 1:].contiguous().view(-1).to(DEVICE)\n",
        "        src_pad_mask = (src == PAD).view(src.size(0), 1, 1, src.size(-1))\n",
        "        trg_pad_mask = (trg_in == PAD).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n",
        "        return src, trg_in, trg_out, src_pad_mask, trg_pad_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d0LvR6cbuiS"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloaders):\n",
        "    model.train()\n",
        "    grad_norm_clip = 1.0\n",
        "    losses, acc, count = [], 0, 0\n",
        "    num_batches = len(dataloaders.train_loader)\n",
        "    pbar = tqdm(enumerate(dataloaders.train_loader), total=num_batches)\n",
        "    for idx, (x, y)  in  pbar:\n",
        "        optimizer.zero_grad()\n",
        "        src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n",
        "        pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n",
        "        pred = pred.view(-1, pred.size(-1))\n",
        "        loss = loss_fn(pred, trg_out).to(DEVICE)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        losses.append(loss.item())\n",
        "        # report progress\n",
        "        if idx>0 and idx%50 == 0:\n",
        "            pbar.set_description(f'train loss={loss.item():.3f}, lr={scheduler.get_last_lr()[0]:.5f}')\n",
        "    return np.mean(losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9woKUsDebuiS"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloaders, epochs):\n",
        "    global early_stop_count\n",
        "    best_valid_loss = float('inf')\n",
        "    train_size = len(dataloaders.train_loader)*batch_size\n",
        "    for ep in range(epochs):\n",
        "        train_loss = train_epoch(model, dataloaders)\n",
        "        valid_loss = validate(model, dataloaders.valid_loader)\n",
        "\n",
        "        print(f'ep: {ep}: train_loss={train_loss:.5f}, valid_loss={valid_loss:.5f}')\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "        else:\n",
        "            if scheduler.last_epoch>2*warmup_steps:\n",
        "                early_stop_count -= 1\n",
        "                if early_stop_count<=0:\n",
        "                    return train_loss, valid_loss\n",
        "    return train_loss, valid_loss\n",
        "\n",
        "\n",
        "def validate(model, dataloder):\n",
        "    'compute the validation loss'\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(dataloder):\n",
        "            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n",
        "            pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n",
        "            pred = pred.view(-1, pred.size(-1))\n",
        "            losses.append(loss_fn(pred, trg_out).item())\n",
        "    return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh5HZ00AbuiS"
      },
      "outputs": [],
      "source": [
        "def translate(model, x):\n",
        "    'translate source sentences into the target language, without looking at the answer'\n",
        "    with torch.no_grad():\n",
        "        dB = x.size(0)\n",
        "        y = torch.tensor([[BOS]*dB]).view(dB, 1).to(DEVICE)\n",
        "        x_pad_mask = (x == PAD).view(x.size(0), 1, 1, x.size(-1)).to(DEVICE)\n",
        "        memory = model.encoder(x, x_pad_mask)\n",
        "        for i in range(max_seq_len):\n",
        "            y_pad_mask = (y == PAD).view(y.size(0), 1, 1, y.size(-1)).to(DEVICE)\n",
        "            logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n",
        "            last_output = logits.argmax(-1)[:, -1]\n",
        "            last_output = last_output.view(dB, 1)\n",
        "            y = torch.cat((y, last_output), 1).to(DEVICE)\n",
        "    return y\n",
        "\n",
        "def remove_pad(sent):\n",
        "    if sent.count(EOS) > 0:\n",
        "        sent = sent[0:sent.index(EOS) + 1]\n",
        "    while sent and sent[-1] == PAD:\n",
        "        sent = sent[:-1]\n",
        "    return sent\n",
        "\n",
        "\n",
        "def decode_sentence(detokenizer,sentence_ids):\n",
        "    if not isinstance(sentence_ids,list):\n",
        "        sentence_ids = sentence_ids.tolist()\n",
        "    sentence_ids = remove_pad(sentence_ids)\n",
        "    return detokenizer(sentence_ids).replace(\"<bos>\",\"\").replace(\"<eos>\",\"\").strip().replace(\" .\",\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L26olex1buiS"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, num_batch=None):\n",
        "    'evaluate the model, and compute the BLEU score'\n",
        "    model.eval()\n",
        "    refs, cans, bleus = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for idx, (x, y) in enumerate(dataloader):\n",
        "            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n",
        "            translation = translate(model, src)\n",
        "            trg_out = trg_out.view(x.size(0), -1)\n",
        "            refs = refs + [decode_sentence(detokenizers[TRG], trg_out[i]) for i in range(len(src))]\n",
        "            cans = cans + [decode_sentence(detokenizers[TRG], translation[i]) for i in range(len(src))]\n",
        "            if num_batch and idx>=num_batch:\n",
        "                break\n",
        "        print(min([len(x) for x in refs]))\n",
        "        bleus.append(sacrebleu.corpus_bleu(cans, [refs]).score)\n",
        "        # print some examples\n",
        "        for i in range(3):\n",
        "            print(f'src:  {decode_sentence(detokenizers[SRC], src[i])}')\n",
        "            print(f'trg:  {decode_sentence(detokenizers[TRG], trg_out[i])}')\n",
        "            print(f'pred: {decode_sentence(detokenizers[TRG], translation[i])}')\n",
        "        return np.mean(bleus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1G8BV-RbuiS",
        "outputId": "563feff0-1a50-47f8-acf9-32d80c18d9f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_size: 26201096, train_set_size: 29056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=4.001, lr=0.00025: 100%|██████████| 227/227 [00:35<00:00,  6.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0: train_loss=5.62009, valid_loss=3.82575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=2.733, lr=0.00053: 100%|██████████| 227/227 [00:35<00:00,  6.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 1: train_loss=3.30335, valid_loss=2.76759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=2.245, lr=0.00082: 100%|██████████| 227/227 [00:34<00:00,  6.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 2: train_loss=2.38205, valid_loss=2.18586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.664, lr=0.00074: 100%|██████████| 227/227 [00:35<00:00,  6.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 3: train_loss=1.84586, valid_loss=1.91751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.611, lr=0.00066: 100%|██████████| 227/227 [00:34<00:00,  6.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 4: train_loss=1.47627, valid_loss=1.80372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.314, lr=0.00060: 100%|██████████| 227/227 [00:34<00:00,  6.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 5: train_loss=1.22688, valid_loss=1.78247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.124, lr=0.00056: 100%|██████████| 227/227 [00:35<00:00,  6.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 6: train_loss=1.04471, valid_loss=1.78388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.080, lr=0.00052: 100%|██████████| 227/227 [00:34<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 7: train_loss=0.90393, valid_loss=1.79571\n",
            "train set examples:\n",
            "22\n",
            "src:  Ein junges Mädchen ist im Freien und guckt sich Kleider an.\n",
            "trg:  A young girl is outdoors looks at gowns.\n",
            "pred: A young girl is outside looking at clothes.\n",
            "src:  Der weiß-braune Hund schüttelt seine Ohren.\n",
            "trg:  The white and brown dog is shaking its ears.\n",
            "pred: The white and brown dog is shaking its ears.\n",
            "src:  Ein schickes Mädchen spricht mit dem Handy während sie langsam die Straße entlangschwebt.\n",
            "trg:  A trendy girl talking on her cellphone while gliding slowly down the street.\n",
            "pred: A fancy girl talks on her cellphone while gliding slowly down the street.\n",
            "validation set examples:\n",
            "20\n",
            "src:  Eine Person in einem roten Langarmshirt liegt auf sehr ungewöhnliche Art auf einer Mauer vor einem Laternenpfahl.\n",
            "trg:  A person wearing a red long-sleeved shirt is lying down on a wall in front of a lamp post in a very unusual manner.\n",
            "pred: A person with a red long-hair is laying on a wall in front of some kinds of odd on a wall.\n",
            "src:  Eine Frau zieht einem kleinen Mädchen einen Helm an.\n",
            "trg:  A woman is putting a helmet on a small girl.\n",
            "pred: A woman pulls a little girl in a helmet.\n",
            "src:  Drei Männer gehen zu Fuß bei einem Zelt mit einem Werbeschild daran.\n",
            "trg:  Three men walking next to a tent with a billboard sign on it.\n",
            "pred: Three men are walking in a tent with a \"T visor.\"\n"
          ]
        }
      ],
      "source": [
        "config = ModelConfig(encoder_vocab_size = vocab_sizes[SRC],\n",
        "                     decoder_vocab_size=vocab_sizes[TRG],\n",
        "                     d_embed=512,\n",
        "                     d_ff=512,\n",
        "                     h=8,\n",
        "                     N_encoder=3,  # 6\n",
        "                     N_decoder=3,  # 6\n",
        "                     max_seq_len=max_seq_len, #50\n",
        "                     dropout=0.1\n",
        "                     )\n",
        "\n",
        "data_loaders = Dataloaders()\n",
        "train_size = len(data_loaders.train_loader)*batch_size\n",
        "model = make_model(config)\n",
        "model_size = sum([p.numel() for p in model.parameters()])\n",
        "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
        "\n",
        "warmup_steps = 3*len(data_loaders.train_loader)\n",
        "# lr first increases in the warmup steps, and then descreases\n",
        "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
        "early_stop_count = 2\n",
        "train_loss, valid_loss = train(model, data_loaders, epochs=10)\n",
        "\n",
        "print(\"train set examples:\")\n",
        "train_bleu = evaluate(model, data_loaders.train_loader, 20)\n",
        "print(\"validation set examples:\")\n",
        "valid_bleu = evaluate(model, data_loaders.valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAzf_ps2buiS"
      },
      "outputs": [],
      "source": [
        "def translate_this_sentence(text: str):\n",
        "    'translate the source sentence in string formate into target language'\n",
        "    input = torch.tensor([[BOS] + tokenizers[SRC](text) + [EOS]]).to(DEVICE)\n",
        "    output = translate(model, input)\n",
        "    return decode_sentence(detokenizers[TRG], output[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5M2uZFBYbuiS",
        "outputId": "66ced304-db33-4cba-853a-c67ea645827d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A group of people standing in front of an igloo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 245
        }
      ],
      "source": [
        "translate_this_sentence(\"Eine Gruppe von Menschen steht vor einem Iglu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jupchm11buiS",
        "outputId": "5caf7134-b301-4ad7-d822-2d528346e6f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Enen walks down just directd by.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 246
        }
      ],
      "source": [
        "translate_this_sentence(\"Wie geht es dir \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jx5ye4c6iR2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}